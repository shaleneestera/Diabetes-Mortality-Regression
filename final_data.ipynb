{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa939fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building final diabetes regression dataset (city-year 2018–2021)...\n",
      "    adm3_pcode     city_name    year  diab_deaths  diab_death_rate  \\\n",
      "0  PH015518000  Dagupan City  2018.0           95        46.903383   \n",
      "1  PH015518000  Dagupan City  2019.0           87        42.953625   \n",
      "2  PH015518000  Dagupan City  2020.0          100        49.371982   \n",
      "3  PH015518000  Dagupan City  2021.0          101        49.865702   \n",
      "4  PH034919000  Palayan City  2018.0            3         5.618694   \n",
      "\n",
      "        pop_mean  nightlights_log  mean_temp_c  pm25_mean  \\\n",
      "0  202544.024373         1.902008    27.692509  18.295625   \n",
      "1  202544.024373         1.920269    27.569729  19.399861   \n",
      "2  202544.024373         1.909537    28.005887  18.576250   \n",
      "3  202544.024373         1.849594    27.952760  19.580903   \n",
      "4   53393.188070        -0.166533    26.663969  28.506042   \n",
      "\n",
      "   hospital_nearest_mean  wealth_index_city  high_poverty  \n",
      "0             458.801367           0.636998             0  \n",
      "1             458.801367           0.636998             0  \n",
      "2             458.801367           0.636998             0  \n",
      "3             461.464381           0.636998             0  \n",
      "4            7898.372814           0.446820             1  \n",
      "Shape: (48, 12)\n",
      "Saved dataset to: diabetes_regression_city_year_2018_2021.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#BASE_DIR = Path(r\"/path/to/your/cchain_folder\")  # <<< CHANGE THIS\n",
    "\n",
    "LOCATION_FILE    = \"location.csv\"              # the file you uploaded\n",
    "WORLDPOP_FILE    = \"worldpop_population.csv\"\n",
    "PSA_FILE         = \"disease_psa_totals.csv\"\n",
    "NIGHTLIGHTS_FILE = \"nighttime_lights.csv\"\n",
    "HEALTH_FILE      = \"osm_poi_health.csv\"     # file with hospital_nearest\n",
    "RWI_FILE         = \"tm_relative_wealth_index.csv\"\n",
    "CLIMATE_FILE     = \"climate_atmosphere.csv\"\n",
    "AIRQ_FILE        = \"climate_air_quality.csv\"\n",
    "\n",
    "YEAR_MIN = 2018\n",
    "YEAR_MAX = 2021\n",
    "\n",
    "# ============================================================\n",
    "# COLUMN NAMES (BASED ON YOUR DESCRIPTION)\n",
    "# ============================================================\n",
    "\n",
    "COL_CITY_ID   = \"adm3_pcode\"\n",
    "COL_ADM4      = \"adm4_pcode\"\n",
    "COL_DATE      = \"date\"\n",
    "COL_YEAR      = \"year\"\n",
    "\n",
    "# WorldPop\n",
    "COL_POP_TOTAL = \"pop_count_total\"\n",
    "\n",
    "# PSA\n",
    "COL_DISEASE_COMMON = \"disease_common_name\"\n",
    "COL_DEATH_TOTAL    = \"death_total\"\n",
    "DIABETES_KEYWORD   = \"diabet\"   # will match \"DIABETES\", \"Diabetes Mellitus\", etc. (case-insensitive)\n",
    "\n",
    "# Nightlights\n",
    "COL_NTL_MEAN = \"avg_rad_mean\"\n",
    "\n",
    "# Health facilities\n",
    "COL_HOSP_NEAREST = \"hospital_nearest\"\n",
    "\n",
    "# Wealth index\n",
    "COL_RWI_MEAN = \"rwi_mean\"\n",
    "\n",
    "# Climate\n",
    "COL_TAVE = \"tave\"   # daily average temp\n",
    "\n",
    "# Air quality\n",
    "COL_PM25 = \"pm25\"\n",
    "\n",
    "# ============================================================\n",
    "# LOCATION MAPPING (adm4 → adm3 + city_name)\n",
    "# ============================================================\n",
    "\n",
    "_location_map = None\n",
    "\n",
    "def load_location():\n",
    "    \"\"\"\n",
    "    Load location.csv and return mapping:\n",
    "    adm4_pcode → adm3_pcode + city_name\n",
    "    \"\"\"\n",
    "    global _location_map\n",
    "    if _location_map is None:\n",
    "        loc = pd.read_csv(LOCATION_FILE)\n",
    "        # adjust these three column names if needed\n",
    "        loc = loc[[COL_ADM4, COL_CITY_ID, \"adm3_en\"]].drop_duplicates()\n",
    "        loc = loc.rename(columns={\"adm3_en\": \"city_name\"})\n",
    "        _location_map = loc\n",
    "    return _location_map\n",
    "\n",
    "\n",
    "def ensure_city_id(df, df_name=\"df\"):\n",
    "    \"\"\"\n",
    "    Ensure df has COL_CITY_ID. If not, but has adm4_pcode, merge from location.csv.\n",
    "    \"\"\"\n",
    "    if COL_CITY_ID in df.columns:\n",
    "        return df\n",
    "    if COL_ADM4 in df.columns:\n",
    "        loc = load_location()\n",
    "        df = df.merge(loc[[COL_ADM4, COL_CITY_ID]], on=COL_ADM4, how=\"left\")\n",
    "        return df\n",
    "    raise KeyError(f\"{df_name} has neither '{COL_CITY_ID}' nor '{COL_ADM4}'.\")\n",
    "\n",
    "\n",
    "def restrict_years(df, year_col=COL_YEAR, year_min=YEAR_MIN, year_max=YEAR_MAX):\n",
    "    return df[(df[year_col] >= year_min) & (df[year_col] <= year_max)].copy()\n",
    "\n",
    "# ============================================================\n",
    "# 1. Population: city-level pop_mean from WorldPop (2018–2020)\n",
    "# ============================================================\n",
    "\n",
    "def build_city_pop_mean():\n",
    "    \"\"\"\n",
    "    Compute city-level mean population (pop_mean) using WorldPop.\n",
    "    WorldPop has adm4 + date; we:\n",
    "    - map adm4 → adm3\n",
    "    - extract year from date\n",
    "    - keep 2018–2020\n",
    "    - sum pop_count_total per city-year\n",
    "    - average across years → pop_mean per city\n",
    "    \"\"\"\n",
    "    pop = pd.read_csv(WORLDPOP_FILE)\n",
    "    pop = ensure_city_id(pop, df_name=\"WorldPop\")\n",
    "\n",
    "    pop[COL_DATE] = pd.to_datetime(pop[COL_DATE], errors=\"coerce\", dayfirst=True)\n",
    "    pop[COL_YEAR] = pop[COL_DATE].dt.year\n",
    "\n",
    "    pop = pop[(pop[COL_YEAR] >= 2018) & (pop[COL_YEAR] <= 2020)].copy()\n",
    "\n",
    "    pop_city_year = (\n",
    "        pop.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_POP_TOTAL]\n",
    "           .sum()\n",
    "           .rename(columns={COL_POP_TOTAL: \"pop_total\"})\n",
    "    )\n",
    "\n",
    "    pop_city_mean = (\n",
    "        pop_city_year.groupby(COL_CITY_ID, as_index=False)[\"pop_total\"]\n",
    "                     .mean()\n",
    "                     .rename(columns={\"pop_total\": \"pop_mean\"})\n",
    "    )\n",
    "\n",
    "    return pop_city_mean\n",
    "\n",
    "# ============================================================\n",
    "# 2. PSA diabetes deaths → diab_death_rate\n",
    "# ============================================================\n",
    "\n",
    "def build_psa_deaths(pop_city):\n",
    "    \"\"\"\n",
    "    Build city-year diabetes deaths and death rate per 100k using PSA.\n",
    "    \"\"\"\n",
    "    psa = pd.read_csv(PSA_FILE)\n",
    "    psa = ensure_city_id(psa, df_name=\"PSA\")\n",
    "\n",
    "    psa[COL_DATE] = pd.to_datetime(psa[COL_DATE], errors=\"coerce\", dayfirst=True)\n",
    "    psa[COL_YEAR] = psa[COL_DATE].dt.year\n",
    "\n",
    "    psa = restrict_years(psa, COL_YEAR)\n",
    "\n",
    "    # filter disease_common_name containing \"diabet\"\n",
    "    psa = psa[psa[COL_DISEASE_COMMON].str.contains(DIABETES_KEYWORD,\n",
    "                                                   case=False,\n",
    "                                                   na=False)].copy()\n",
    "\n",
    "    deaths_city_year = (\n",
    "        psa.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_DEATH_TOTAL]\n",
    "           .sum()\n",
    "           .rename(columns={COL_DEATH_TOTAL: \"diab_deaths\"})\n",
    "    )\n",
    "\n",
    "    deaths_city_year = deaths_city_year.merge(pop_city, on=COL_CITY_ID, how=\"left\")\n",
    "\n",
    "    deaths_city_year[\"diab_death_rate\"] = (\n",
    "        deaths_city_year[\"diab_deaths\"] / deaths_city_year[\"pop_mean\"] * 100_000\n",
    "    )\n",
    "\n",
    "    return deaths_city_year\n",
    "\n",
    "# ============================================================\n",
    "# 3. Nightlights → nightlights_log\n",
    "# ============================================================\n",
    "\n",
    "def build_nightlights():\n",
    "    \"\"\"\n",
    "    Build city-year nightlights_log from nighttime_lights (adm4-level yearly).\n",
    "    \"\"\"\n",
    "    nl = pd.read_csv(NIGHTLIGHTS_FILE)\n",
    "    nl = ensure_city_id(nl, df_name=\"Nightlights\")\n",
    "\n",
    "    # if year isn't present but date is, derive it\n",
    "    if COL_YEAR not in nl.columns and COL_DATE in nl.columns:\n",
    "        nl[COL_DATE] = pd.to_datetime(nl[COL_DATE], errors=\"coerce\", dayfirst=True)\n",
    "        nl[COL_YEAR] = nl[COL_DATE].dt.year\n",
    "\n",
    "    nl = restrict_years(nl, COL_YEAR)\n",
    "\n",
    "    nl_city_year = (\n",
    "        nl.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_NTL_MEAN]\n",
    "          .mean()\n",
    "          .rename(columns={COL_NTL_MEAN: \"nightlights_mean\"})\n",
    "    )\n",
    "\n",
    "    eps = 1e-6\n",
    "    nl_city_year[\"nightlights_log\"] = np.log(\n",
    "        nl_city_year[\"nightlights_mean\"].clip(lower=0) + eps\n",
    "    )\n",
    "\n",
    "    return nl_city_year[[COL_CITY_ID, COL_YEAR, \"nightlights_log\"]]\n",
    "\n",
    "# ============================================================\n",
    "# 4. Health access → hospital_nearest_mean\n",
    "# ============================================================\n",
    "\n",
    "def build_health_access():\n",
    "    \"\"\"\n",
    "    Build city-year mean distance/time to nearest hospital (hospital_nearest_mean).\n",
    "    \"\"\"\n",
    "    hf = pd.read_csv(HEALTH_FILE)\n",
    "    hf = ensure_city_id(hf, df_name=\"Health facilities\")\n",
    "\n",
    "    if COL_YEAR not in hf.columns and COL_DATE in hf.columns:\n",
    "        hf[COL_DATE] = pd.to_datetime(hf[COL_DATE], errors=\"coerce\", dayfirst=True)\n",
    "        hf[COL_YEAR] = hf[COL_DATE].dt.year\n",
    "\n",
    "    hf = restrict_years(hf, COL_YEAR)\n",
    "\n",
    "    hf_city_year = (\n",
    "        hf.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_HOSP_NEAREST]\n",
    "          .mean()\n",
    "          .rename(columns={COL_HOSP_NEAREST: \"hospital_nearest_mean\"})\n",
    "    )\n",
    "\n",
    "    return hf_city_year[[COL_CITY_ID, COL_YEAR, \"hospital_nearest_mean\"]]\n",
    "\n",
    "# ============================================================\n",
    "# 5. Wealth index → wealth_index_city + high_poverty\n",
    "# ============================================================\n",
    "\n",
    "def build_wealth_and_dummy():\n",
    "    \"\"\"\n",
    "    Build city-level wealth_index_city (mean rwi_mean) and high_poverty dummy.\n",
    "    \"\"\"\n",
    "    rwi = pd.read_csv(RWI_FILE)\n",
    "    rwi = ensure_city_id(rwi, df_name=\"RWI\")\n",
    "\n",
    "    city_wealth = (\n",
    "        rwi.groupby(COL_CITY_ID, as_index=False)[COL_RWI_MEAN]\n",
    "           .mean()\n",
    "           .rename(columns={COL_RWI_MEAN: \"wealth_index_city\"})\n",
    "    )\n",
    "\n",
    "    median_val = city_wealth[\"wealth_index_city\"].median()\n",
    "    city_wealth[\"high_poverty\"] = (\n",
    "        city_wealth[\"wealth_index_city\"] < median_val\n",
    "    ).astype(int)\n",
    "\n",
    "    return city_wealth[[COL_CITY_ID, \"wealth_index_city\", \"high_poverty\"]]\n",
    "\n",
    "# ============================================================\n",
    "# 6. Climate → mean_temp_c (tave)\n",
    "# ============================================================\n",
    "\n",
    "def build_mean_temp():\n",
    "    \"\"\"\n",
    "    Build city-year mean_temp_c from climate_atmosphere (daily tave, adm4).\n",
    "    \"\"\"\n",
    "    clim = pd.read_csv(CLIMATE_FILE)\n",
    "    clim = ensure_city_id(clim, df_name=\"Climate\")\n",
    "\n",
    "    clim[COL_DATE] = pd.to_datetime(clim[COL_DATE], errors=\"coerce\", dayfirst=True)\n",
    "    clim[COL_YEAR] = clim[COL_DATE].dt.year\n",
    "    clim = restrict_years(clim, COL_YEAR)\n",
    "\n",
    "    temp_city_year = (\n",
    "        clim.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_TAVE]\n",
    "             .mean()\n",
    "             .rename(columns={COL_TAVE: \"mean_temp_c\"})\n",
    "    )\n",
    "\n",
    "    return temp_city_year[[COL_CITY_ID, COL_YEAR, \"mean_temp_c\"]]\n",
    "\n",
    "# ============================================================\n",
    "# 7. Air quality → pm25_mean\n",
    "# ============================================================\n",
    "\n",
    "def build_pm25():\n",
    "    \"\"\"\n",
    "    Build city-year pm25_mean from climate_air_quality (daily pm25, adm4).\n",
    "    \"\"\"\n",
    "    air = pd.read_csv(AIRQ_FILE)\n",
    "    air = ensure_city_id(air, df_name=\"Air quality\")\n",
    "\n",
    "    air[COL_DATE] = pd.to_datetime(air[COL_DATE], errors=\"coerce\", dayfirst=True)\n",
    "    air[COL_YEAR] = air[COL_DATE].dt.year\n",
    "    air = restrict_years(air, COL_YEAR)\n",
    "\n",
    "    pm_city_year = (\n",
    "        air.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_PM25]\n",
    "           .mean()\n",
    "           .rename(columns={COL_PM25: \"pm25_mean\"})\n",
    "    )\n",
    "\n",
    "    return pm_city_year[[COL_CITY_ID, COL_YEAR, \"pm25_mean\"]]\n",
    "\n",
    "# ============================================================\n",
    "# 8. Build final dataset (city-year 2018–2021)\n",
    "# ============================================================\n",
    "\n",
    "def build_final_dataset():\n",
    "    # City-level pop_mean\n",
    "    pop_city = build_city_pop_mean()\n",
    "\n",
    "    # Core pieces\n",
    "    deaths = build_psa_deaths(pop_city)   # diab_deaths, diab_death_rate, pop_mean\n",
    "    night  = build_nightlights()          # nightlights_log\n",
    "    temp   = build_mean_temp()            # mean_temp_c\n",
    "    pm25   = build_pm25()                 # pm25_mean\n",
    "    wealth = build_wealth_and_dummy()     # wealth_index_city, high_poverty\n",
    "    hosp   = build_health_access()        # hospital_nearest_mean\n",
    "\n",
    "    # Start from deaths\n",
    "    df = deaths.copy()\n",
    "\n",
    "    # Merge city-year predictors\n",
    "    for other in [night, temp, pm25, hosp]:\n",
    "        df = df.merge(other, on=[COL_CITY_ID, COL_YEAR], how=\"left\")\n",
    "\n",
    "    # Merge city-level predictors\n",
    "    df = df.merge(wealth, on=COL_CITY_ID, how=\"left\")\n",
    "\n",
    "    # Add city_name from location\n",
    "    loc = load_location()[[COL_CITY_ID, \"city_name\"]].drop_duplicates()\n",
    "    df = df.merge(loc, on=COL_CITY_ID, how=\"left\")\n",
    "\n",
    "    df = restrict_years(df, COL_YEAR)\n",
    "    df = df[~df[\"diab_death_rate\"].isna()].copy()\n",
    "\n",
    "    final_cols = [\n",
    "        COL_CITY_ID,\n",
    "        \"city_name\",\n",
    "        COL_YEAR,\n",
    "        \"diab_deaths\",\n",
    "        \"diab_death_rate\",\n",
    "        \"pop_mean\",\n",
    "        \"nightlights_log\",\n",
    "        \"mean_temp_c\",\n",
    "        \"pm25_mean\",\n",
    "        \"hospital_nearest_mean\",\n",
    "        \"wealth_index_city\",\n",
    "        \"high_poverty\",\n",
    "    ]\n",
    "\n",
    "    missing = [c for c in final_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        print(\"Warning: these expected columns are missing:\", missing)\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "    df_final = df[[c for c in final_cols if c in df.columns]]\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Final dataset:\")\n",
    "    df_final = build_final_dataset()\n",
    "    print(df_final.head())\n",
    "    print(\"Shape:\", df_final.shape)\n",
    "\n",
    "    out_path = \"diabetes_regression_city_year_2018_2021.csv\"\n",
    "    df_final.to_csv(out_path, index=False)\n",
    "    print(\"Saved dataset to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc2b6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nimport numpy as np\\nfrom pathlib import Path\\n\\n# ============================================================\\n# CONFIG – EDIT THESE TO MATCH YOUR FOLDER / FILENAMES\\n# ============================================================\\n\\n\\nLOCATION_FILE    = \"location.csv\"              # the file you uploaded\\nWORLDPOP_FILE    = \"worldpop_population.csv\"\\nPSA_FILE         = \"disease_psa_totals.csv\"\\nNIGHTLIGHTS_FILE = \"nighttime_lights.csv\"\\nHEALTH_FILE      = \"health_facilities.csv\"     # file with hospital_nearest\\nRWI_FILE         = \"tm_relative_wealth_index.csv\"\\nCLIMATE_FILE     = \"climate_atmosphere.csv\"\\nAIRQ_FILE        = \"climate_air_quality.csv\"\\n\\nYEAR_MIN = 2018\\nYEAR_MAX = 2021\\n\\n# ============================================================\\n# COLUMN NAMES (MATCHING YOUR DESCRIPTION)\\n# ============================================================\\n\\nCOL_CITY_ID   = \"adm3_pcode\"\\nCOL_ADM4      = \"adm4_pcode\"\\nCOL_DATE      = \"date\"\\nCOL_YEAR      = \"year\"\\n\\n# WorldPop\\nCOL_POP_TOTAL = \"pop_count_total\"\\n\\n# PSA\\nCOL_DISEASE_COMMON = \"disease_common_name\"\\nCOL_DEATH_TOTAL    = \"death_total\"\\nDIABETES_KEYWORD   = \"diabet\"   # match \"diabet\" in disease_common_name (case-insensitive)\\n\\n# Nightlights\\nCOL_NTL_MEAN = \"avg_rad_mean\"\\n\\n# Health facilities\\nCOL_HOSP_NEAREST = \"hospital_nearest\"\\n\\n# Wealth index\\nCOL_RWI_MEAN = \"rwi_mean\"\\n\\n# Climate\\nCOL_TAVE = \"tave\"   # daily average temp\\n\\n# Air quality\\nCOL_PM25 = \"pm25\"\\n\\n\\n# ============================================================\\n# LOCATION MAPPING (adm4 → adm3 + city_name)\\n# ============================================================\\n\\n_location_map = None\\n\\ndef load_location():\\n    \"\"\"\\n    Load location.csv and return a mapping:\\n    adm4_pcode → adm3_pcode + city_name\\n    \"\"\"\\n    global _location_map\\n    if _location_map is None:\\n        loc = pd.read_csv(LOCATION_FILE)\\n        # Expect columns like: adm3_pcode, adm3_en, adm4_pcode, ...\\n        loc = loc[[COL_ADM4, COL_CITY_ID, \"adm3_en\"]].drop_duplicates()\\n        loc = loc.rename(columns={\"adm3_en\": \"city_name\"})\\n        _location_map = loc\\n    return _location_map\\n\\n\\ndef ensure_city_id(df, df_name=\"df\"):\\n    \"\"\"\\n    Make sure df has COL_CITY_ID. If not, but it has adm4_pcode,\\n    merge from location.csv.\\n    \"\"\"\\n    if COL_CITY_ID in df.columns:\\n        return df\\n    if COL_ADM4 in df.columns:\\n        loc = load_location()\\n        df = df.merge(loc[[COL_ADM4, COL_CITY_ID]], on=COL_ADM4, how=\"left\")\\n        return df\\n    raise KeyError(f\"{df_name} has neither \\'{COL_CITY_ID}\\' nor \\'{COL_ADM4}\\'.\")\\n\\n\\ndef restrict_years(df, year_col=COL_YEAR, year_min=YEAR_MIN, year_max=YEAR_MAX):\\n    return df[(df[year_col] >= year_min) & (df[year_col] <= year_max)].copy()\\n\\n\\n# ============================================================\\n# 1. Population: city-level pop_mean from WorldPop (2018–2020)\\n# ============================================================\\n\\ndef build_city_pop_mean():\\n    \"\"\"\\n    Use WorldPop (adm4, daily) to compute a city-level mean population (pop_mean)\\n    over 2018–2020. We treat this as constant population for 2018–2021.\\n    \"\"\"\\n    pop = pd.read_csv(WORLDPOP_FILE, parse_dates=[COL_DATE])\\n    # Ensure we have city id\\n    pop = ensure_city_id(pop, df_name=\"WorldPop\")\\n\\n    # Create \\'year\\' from \\'date\\'\\n    pop[COL_YEAR] = pop[COL_DATE].dt.year\\n\\n    # Keep only 2018–2020\\n    pop = pop[(pop[COL_YEAR] >= 2018) & (pop[COL_YEAR] <= 2020)].copy()\\n\\n    # Sum barangay (adm4) populations to city-year totals\\n    pop_city_year = (\\n        pop.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_POP_TOTAL]\\n           .sum()\\n           .rename(columns={COL_POP_TOTAL: \"pop_total\"})\\n    )\\n\\n    # Average over years per city → pop_mean\\n    pop_city_mean = (\\n        pop_city_year.groupby(COL_CITY_ID, as_index=False)[\"pop_total\"]\\n                     .mean()\\n                     .rename(columns={\"pop_total\": \"pop_mean\"})\\n    )\\n\\n    return pop_city_mean\\n\\n\\n# ============================================================\\n# 2. PSA diabetes deaths → diab_death_rate\\n# ============================================================\\n\\ndef build_psa_deaths(pop_city):\\n    \"\"\"\\n    Build city-year diabetes deaths and death rate per 100k using PSA.\\n    \"\"\"\\n    psa = pd.read_csv(PSA_FILE, parse_dates=[COL_DATE], dayfirst=True)\\n    # Expect: adm3_pcode, date, disease_common_name, death_total, ...\\n\\n    psa = ensure_city_id(psa, df_name=\"PSA\")\\n    psa[COL_YEAR] = psa[COL_DATE].dt.year\\n    psa = restrict_years(psa, COL_YEAR)\\n\\n    # Filter rows where disease_common_name contains \"diabet\"\\n    psa = psa[psa[COL_DISEASE_COMMON].str.contains(DIABETES_KEYWORD,\\n                                                   case=False,\\n                                                   na=False)].copy()\\n\\n    # Sum weekly deaths into city-year totals\\n    deaths_city_year = (\\n        psa.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_DEATH_TOTAL]\\n           .sum()\\n           .rename(columns={COL_DEATH_TOTAL: \"diab_deaths\"})\\n    )\\n\\n    # Merge pop_mean per city\\n    deaths_city_year = deaths_city_year.merge(pop_city, on=COL_CITY_ID, how=\"left\")\\n\\n    # Compute death rate per 100,000\\n    deaths_city_year[\"diab_death_rate\"] = (\\n        deaths_city_year[\"diab_deaths\"] / deaths_city_year[\"pop_mean\"] * 100_000\\n    )\\n\\n    return deaths_city_year\\n\\n\\n# ============================================================\\n# 3. Nightlights → nightlights_log\\n# ============================================================\\n\\ndef build_nightlights():\\n    \"\"\"\\n    Build city-year nightlights_log from nighttime_lights (adm4, yearly).\\n    \"\"\"\\n    nl = pd.read_csv(NIGHTLIGHTS_FILE)\\n    # Expect: adm4_pcode, year, avg_rad_mean, ...\\n\\n    nl = ensure_city_id(nl, df_name=\"Nightlights\")\\n    if COL_YEAR not in nl.columns and COL_DATE in nl.columns:\\n        nl[COL_DATE] = pd.to_datetime(nl[COL_DATE])\\n        nl[COL_YEAR] = nl[COL_DATE].dt.year\\n\\n    nl = restrict_years(nl, COL_YEAR)\\n\\n    nl_city_year = (\\n        nl.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_NTL_MEAN]\\n          .mean()\\n          .rename(columns={COL_NTL_MEAN: \"nightlights_mean\"})\\n    )\\n\\n    eps = 1e-6\\n    nl_city_year[\"nightlights_log\"] = np.log(\\n        nl_city_year[\"nightlights_mean\"].clip(lower=0) + eps\\n    )\\n\\n    return nl_city_year[[COL_CITY_ID, COL_YEAR, \"nightlights_log\"]]\\n\\n\\n# ============================================================\\n# 4. Health access → hospital_nearest_mean\\n# ============================================================\\n\\ndef build_health_access():\\n    \"\"\"\\n    Build city-year mean distance/time to nearest hospital (hospital_nearest_mean).\\n    \"\"\"\\n    hf = pd.read_csv(HEALTH_FILE)\\n    # Expect: adm4_pcode, year, hospital_nearest, ...\\n\\n    hf = ensure_city_id(hf, df_name=\"Health facilities\")\\n\\n    if COL_YEAR not in hf.columns and COL_DATE in hf.columns:\\n        hf[COL_DATE] = pd.to_datetime(hf[COL_DATE])\\n        hf[COL_YEAR] = hf[COL_DATE].dt.year\\n\\n    hf = restrict_years(hf, COL_YEAR)\\n\\n    hf_city_year = (\\n        hf.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_HOSP_NEAREST]\\n          .mean()\\n          .rename(columns={COL_HOSP_NEAREST: \"hospital_nearest_mean\"})\\n    )\\n\\n    return hf_city_year[[COL_CITY_ID, COL_YEAR, \"hospital_nearest_mean\"]]\\n\\n\\n# ============================================================\\n# 5. Wealth index → wealth_index_city + high_poverty\\n# ============================================================\\n\\ndef build_wealth_and_dummy():\\n    \"\"\"\\n    Build city-level wealth_index_city (mean rwi_mean) and high_poverty dummy.\\n    \"\"\"\\n    rwi = pd.read_csv(RWI_FILE)\\n    # Expect: adm4_pcode, rwi_mean, ...\\n\\n    rwi = ensure_city_id(rwi, df_name=\"RWI\")\\n\\n    city_wealth = (\\n        rwi.groupby(COL_CITY_ID, as_index=False)[COL_RWI_MEAN]\\n           .mean()\\n           .rename(columns={COL_RWI_MEAN: \"wealth_index_city\"})\\n    )\\n\\n    median_val = city_wealth[\"wealth_index_city\"].median()\\n    city_wealth[\"high_poverty\"] = (\\n        city_wealth[\"wealth_index_city\"] < median_val\\n    ).astype(int)\\n\\n    return city_wealth[[COL_CITY_ID, \"wealth_index_city\", \"high_poverty\"]]\\n\\n\\n# ============================================================\\n# 6. Climate → mean_temp_c (tave)\\n# ============================================================\\n\\ndef build_mean_temp():\\n    \"\"\"\\n    Build city-year mean_temp_c from climate_atmosphere (daily tave, adm4).\\n    \"\"\"\\n    clim = pd.read_csv(CLIMATE_FILE, parse_dates=[COL_DATE], dayfirst=True)\\n    # Expect: adm4_pcode, date, tave, ...\\n\\n    clim = ensure_city_id(clim, df_name=\"Climate\")\\n    clim[COL_YEAR] = clim[COL_DATE].dt.year\\n    clim = restrict_years(clim, COL_YEAR)\\n\\n    temp_city_year = (\\n        clim.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_TAVE]\\n             .mean()\\n             .rename(columns={COL_TAVE: \"mean_temp_c\"})\\n    )\\n\\n    return temp_city_year[[COL_CITY_ID, COL_YEAR, \"mean_temp_c\"]]\\n\\n\\n# ============================================================\\n# 7. Air quality → pm25_mean\\n# ============================================================\\n\\ndef build_pm25():\\n    \"\"\"\\n    Build city-year pm25_mean from climate_air_quality (daily pm25, adm4).\\n    \"\"\"\\n    air = pd.read_csv(AIRQ_FILE, parse_dates=[COL_DATE], dayfirst=True)\\n    # Expect: adm4_pcode, date, pm25, ...\\n\\n    air = ensure_city_id(air, df_name=\"Air quality\")\\n    air[COL_YEAR] = air[COL_DATE].dt.year\\n    air = restrict_years(air, COL_YEAR)\\n\\n    pm_city_year = (\\n        air.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_PM25]\\n           .mean()\\n           .rename(columns={COL_PM25: \"pm25_mean\"})\\n    )\\n\\n    return pm_city_year[[COL_CITY_ID, COL_YEAR, \"pm25_mean\"]]\\n\\n\\n# ============================================================\\n# 8. Build final dataset (city-year 2018–2021)\\n# ============================================================\\n\\ndef build_final_dataset():\\n    # City-level pop_mean\\n    pop_city = build_city_pop_mean()\\n\\n    # Core pieces\\n    deaths = build_psa_deaths(pop_city)   # diab_deaths, diab_death_rate, pop_mean\\n    night  = build_nightlights()          # nightlights_log\\n    temp   = build_mean_temp()            # mean_temp_c\\n    pm25   = build_pm25()                 # pm25_mean\\n    wealth = build_wealth_and_dummy()     # wealth_index_city, high_poverty\\n    hosp   = build_health_access()        # hospital_nearest_mean\\n\\n    # Start from deaths\\n    df = deaths.copy()\\n\\n    # Merge city-year predictors\\n    for other in [night, temp, pm25, hosp]:\\n        df = df.merge(other, on=[COL_CITY_ID, COL_YEAR], how=\"left\")\\n\\n    # Merge city-level predictors\\n    df = df.merge(wealth, on=COL_CITY_ID, how=\"left\")\\n\\n    # Add city_name from location\\n    loc = load_location()[[COL_CITY_ID, \"city_name\"]].drop_duplicates()\\n    df = df.merge(loc, on=COL_CITY_ID, how=\"left\")\\n\\n    # Keep only rows with non-missing death rate\\n    df = restrict_years(df, COL_YEAR)\\n    df = df[~df[\"diab_death_rate\"].isna()].copy()\\n\\n    # Final columns\\n    final_cols = [\\n        COL_CITY_ID,\\n        \"city_name\",\\n        COL_YEAR,\\n        \"diab_deaths\",\\n        \"diab_death_rate\",\\n        \"pop_mean\",\\n        \"nightlights_log\",\\n        \"mean_temp_c\",\\n        \"pm25_mean\",\\n        \"hospital_nearest_mean\",\\n        \"wealth_index_city\",\\n        \"high_poverty\",\\n    ]\\n\\n    missing = [c for c in final_cols if c not in df.columns]\\n    if missing:\\n        print(\"Warning: these expected columns are missing:\", missing)\\n        print(\"Available columns:\", df.columns.tolist())\\n\\n    df_final = df[[c for c in final_cols if c in df.columns]]\\n\\n    return df_final\\n\\n\\n# ============================================================\\n# MAIN\\n# ============================================================\\n\\nif __name__ == \"__main__\":\\n    print(\"Building final diabetes regression dataset (city-year 2018–2021)...\")\\n    df_final = build_final_dataset()\\n    print(df_final.head())\\n    print(\"Shape:\", df_final.shape)\\n\\n    out_path = BASE_DIR / \"diabetes_regression_city_year_2018_2021.csv\"\\n    df_final.to_csv(out_path, index=False)\\n    print(\"Saved dataset to:\", out_path)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG – EDIT THESE TO MATCH YOUR FOLDER / FILENAMES\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "LOCATION_FILE    = \"location.csv\"              # the file you uploaded\n",
    "WORLDPOP_FILE    = \"worldpop_population.csv\"\n",
    "PSA_FILE         = \"disease_psa_totals.csv\"\n",
    "NIGHTLIGHTS_FILE = \"nighttime_lights.csv\"\n",
    "HEALTH_FILE      = \"health_facilities.csv\"     # file with hospital_nearest\n",
    "RWI_FILE         = \"tm_relative_wealth_index.csv\"\n",
    "CLIMATE_FILE     = \"climate_atmosphere.csv\"\n",
    "AIRQ_FILE        = \"climate_air_quality.csv\"\n",
    "\n",
    "YEAR_MIN = 2018\n",
    "YEAR_MAX = 2021\n",
    "\n",
    "# ============================================================\n",
    "# COLUMN NAMES (MATCHING YOUR DESCRIPTION)\n",
    "# ============================================================\n",
    "\n",
    "COL_CITY_ID   = \"adm3_pcode\"\n",
    "COL_ADM4      = \"adm4_pcode\"\n",
    "COL_DATE      = \"date\"\n",
    "COL_YEAR      = \"year\"\n",
    "\n",
    "# WorldPop\n",
    "COL_POP_TOTAL = \"pop_count_total\"\n",
    "\n",
    "# PSA\n",
    "COL_DISEASE_COMMON = \"disease_common_name\"\n",
    "COL_DEATH_TOTAL    = \"death_total\"\n",
    "DIABETES_KEYWORD   = \"diabet\"   # match \"diabet\" in disease_common_name (case-insensitive)\n",
    "\n",
    "# Nightlights\n",
    "COL_NTL_MEAN = \"avg_rad_mean\"\n",
    "\n",
    "# Health facilities\n",
    "COL_HOSP_NEAREST = \"hospital_nearest\"\n",
    "\n",
    "# Wealth index\n",
    "COL_RWI_MEAN = \"rwi_mean\"\n",
    "\n",
    "# Climate\n",
    "COL_TAVE = \"tave\"   # daily average temp\n",
    "\n",
    "# Air quality\n",
    "COL_PM25 = \"pm25\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LOCATION MAPPING (adm4 → adm3 + city_name)\n",
    "# ============================================================\n",
    "\n",
    "_location_map = None\n",
    "\n",
    "def load_location():\n",
    "    \"\"\"\n",
    "    Load location.csv and return a mapping:\n",
    "    adm4_pcode → adm3_pcode + city_name\n",
    "    \"\"\"\n",
    "    global _location_map\n",
    "    if _location_map is None:\n",
    "        loc = pd.read_csv(LOCATION_FILE)\n",
    "        # Expect columns like: adm3_pcode, adm3_en, adm4_pcode, ...\n",
    "        loc = loc[[COL_ADM4, COL_CITY_ID, \"adm3_en\"]].drop_duplicates()\n",
    "        loc = loc.rename(columns={\"adm3_en\": \"city_name\"})\n",
    "        _location_map = loc\n",
    "    return _location_map\n",
    "\n",
    "\n",
    "def ensure_city_id(df, df_name=\"df\"):\n",
    "    \"\"\"\n",
    "    Make sure df has COL_CITY_ID. If not, but it has adm4_pcode,\n",
    "    merge from location.csv.\n",
    "    \"\"\"\n",
    "    if COL_CITY_ID in df.columns:\n",
    "        return df\n",
    "    if COL_ADM4 in df.columns:\n",
    "        loc = load_location()\n",
    "        df = df.merge(loc[[COL_ADM4, COL_CITY_ID]], on=COL_ADM4, how=\"left\")\n",
    "        return df\n",
    "    raise KeyError(f\"{df_name} has neither '{COL_CITY_ID}' nor '{COL_ADM4}'.\")\n",
    "\n",
    "\n",
    "def restrict_years(df, year_col=COL_YEAR, year_min=YEAR_MIN, year_max=YEAR_MAX):\n",
    "    return df[(df[year_col] >= year_min) & (df[year_col] <= year_max)].copy()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Population: city-level pop_mean from WorldPop (2018–2020)\n",
    "# ============================================================\n",
    "\n",
    "def build_city_pop_mean():\n",
    "    \"\"\"\n",
    "    Use WorldPop (adm4, daily) to compute a city-level mean population (pop_mean)\n",
    "    over 2018–2020. We treat this as constant population for 2018–2021.\n",
    "    \"\"\"\n",
    "    pop = pd.read_csv(WORLDPOP_FILE, parse_dates=[COL_DATE])\n",
    "    # Ensure we have city id\n",
    "    pop = ensure_city_id(pop, df_name=\"WorldPop\")\n",
    "\n",
    "    # Create 'year' from 'date'\n",
    "    pop[COL_YEAR] = pop[COL_DATE].dt.year\n",
    "\n",
    "    # Keep only 2018–2020\n",
    "    pop = pop[(pop[COL_YEAR] >= 2018) & (pop[COL_YEAR] <= 2020)].copy()\n",
    "\n",
    "    # Sum barangay (adm4) populations to city-year totals\n",
    "    pop_city_year = (\n",
    "        pop.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_POP_TOTAL]\n",
    "           .sum()\n",
    "           .rename(columns={COL_POP_TOTAL: \"pop_total\"})\n",
    "    )\n",
    "\n",
    "    # Average over years per city → pop_mean\n",
    "    pop_city_mean = (\n",
    "        pop_city_year.groupby(COL_CITY_ID, as_index=False)[\"pop_total\"]\n",
    "                     .mean()\n",
    "                     .rename(columns={\"pop_total\": \"pop_mean\"})\n",
    "    )\n",
    "\n",
    "    return pop_city_mean\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. PSA diabetes deaths → diab_death_rate\n",
    "# ============================================================\n",
    "\n",
    "def build_psa_deaths(pop_city):\n",
    "    \"\"\"\n",
    "    Build city-year diabetes deaths and death rate per 100k using PSA.\n",
    "    \"\"\"\n",
    "    psa = pd.read_csv(PSA_FILE, parse_dates=[COL_DATE], dayfirst=True)\n",
    "    # Expect: adm3_pcode, date, disease_common_name, death_total, ...\n",
    "\n",
    "    psa = ensure_city_id(psa, df_name=\"PSA\")\n",
    "    psa[COL_YEAR] = psa[COL_DATE].dt.year\n",
    "    psa = restrict_years(psa, COL_YEAR)\n",
    "\n",
    "    # Filter rows where disease_common_name contains \"diabet\"\n",
    "    psa = psa[psa[COL_DISEASE_COMMON].str.contains(DIABETES_KEYWORD,\n",
    "                                                   case=False,\n",
    "                                                   na=False)].copy()\n",
    "\n",
    "    # Sum weekly deaths into city-year totals\n",
    "    deaths_city_year = (\n",
    "        psa.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_DEATH_TOTAL]\n",
    "           .sum()\n",
    "           .rename(columns={COL_DEATH_TOTAL: \"diab_deaths\"})\n",
    "    )\n",
    "\n",
    "    # Merge pop_mean per city\n",
    "    deaths_city_year = deaths_city_year.merge(pop_city, on=COL_CITY_ID, how=\"left\")\n",
    "\n",
    "    # Compute death rate per 100,000\n",
    "    deaths_city_year[\"diab_death_rate\"] = (\n",
    "        deaths_city_year[\"diab_deaths\"] / deaths_city_year[\"pop_mean\"] * 100_000\n",
    "    )\n",
    "\n",
    "    return deaths_city_year\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Nightlights → nightlights_log\n",
    "# ============================================================\n",
    "\n",
    "def build_nightlights():\n",
    "    \"\"\"\n",
    "    Build city-year nightlights_log from nighttime_lights (adm4, yearly).\n",
    "    \"\"\"\n",
    "    nl = pd.read_csv(NIGHTLIGHTS_FILE)\n",
    "    # Expect: adm4_pcode, year, avg_rad_mean, ...\n",
    "\n",
    "    nl = ensure_city_id(nl, df_name=\"Nightlights\")\n",
    "    if COL_YEAR not in nl.columns and COL_DATE in nl.columns:\n",
    "        nl[COL_DATE] = pd.to_datetime(nl[COL_DATE])\n",
    "        nl[COL_YEAR] = nl[COL_DATE].dt.year\n",
    "\n",
    "    nl = restrict_years(nl, COL_YEAR)\n",
    "\n",
    "    nl_city_year = (\n",
    "        nl.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_NTL_MEAN]\n",
    "          .mean()\n",
    "          .rename(columns={COL_NTL_MEAN: \"nightlights_mean\"})\n",
    "    )\n",
    "\n",
    "    eps = 1e-6\n",
    "    nl_city_year[\"nightlights_log\"] = np.log(\n",
    "        nl_city_year[\"nightlights_mean\"].clip(lower=0) + eps\n",
    "    )\n",
    "\n",
    "    return nl_city_year[[COL_CITY_ID, COL_YEAR, \"nightlights_log\"]]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Health access → hospital_nearest_mean\n",
    "# ============================================================\n",
    "\n",
    "def build_health_access():\n",
    "    \"\"\"\n",
    "    Build city-year mean distance/time to nearest hospital (hospital_nearest_mean).\n",
    "    \"\"\"\n",
    "    hf = pd.read_csv(HEALTH_FILE)\n",
    "    # Expect: adm4_pcode, year, hospital_nearest, ...\n",
    "\n",
    "    hf = ensure_city_id(hf, df_name=\"Health facilities\")\n",
    "\n",
    "    if COL_YEAR not in hf.columns and COL_DATE in hf.columns:\n",
    "        hf[COL_DATE] = pd.to_datetime(hf[COL_DATE])\n",
    "        hf[COL_YEAR] = hf[COL_DATE].dt.year\n",
    "\n",
    "    hf = restrict_years(hf, COL_YEAR)\n",
    "\n",
    "    hf_city_year = (\n",
    "        hf.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_HOSP_NEAREST]\n",
    "          .mean()\n",
    "          .rename(columns={COL_HOSP_NEAREST: \"hospital_nearest_mean\"})\n",
    "    )\n",
    "\n",
    "    return hf_city_year[[COL_CITY_ID, COL_YEAR, \"hospital_nearest_mean\"]]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Wealth index → wealth_index_city + high_poverty\n",
    "# ============================================================\n",
    "\n",
    "def build_wealth_and_dummy():\n",
    "    \"\"\"\n",
    "    Build city-level wealth_index_city (mean rwi_mean) and high_poverty dummy.\n",
    "    \"\"\"\n",
    "    rwi = pd.read_csv(RWI_FILE)\n",
    "    # Expect: adm4_pcode, rwi_mean, ...\n",
    "\n",
    "    rwi = ensure_city_id(rwi, df_name=\"RWI\")\n",
    "\n",
    "    city_wealth = (\n",
    "        rwi.groupby(COL_CITY_ID, as_index=False)[COL_RWI_MEAN]\n",
    "           .mean()\n",
    "           .rename(columns={COL_RWI_MEAN: \"wealth_index_city\"})\n",
    "    )\n",
    "\n",
    "    median_val = city_wealth[\"wealth_index_city\"].median()\n",
    "    city_wealth[\"high_poverty\"] = (\n",
    "        city_wealth[\"wealth_index_city\"] < median_val\n",
    "    ).astype(int)\n",
    "\n",
    "    return city_wealth[[COL_CITY_ID, \"wealth_index_city\", \"high_poverty\"]]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Climate → mean_temp_c (tave)\n",
    "# ============================================================\n",
    "\n",
    "def build_mean_temp():\n",
    "    \"\"\"\n",
    "    Build city-year mean_temp_c from climate_atmosphere (daily tave, adm4).\n",
    "    \"\"\"\n",
    "    clim = pd.read_csv(CLIMATE_FILE, parse_dates=[COL_DATE], dayfirst=True)\n",
    "    # Expect: adm4_pcode, date, tave, ...\n",
    "\n",
    "    clim = ensure_city_id(clim, df_name=\"Climate\")\n",
    "    clim[COL_YEAR] = clim[COL_DATE].dt.year\n",
    "    clim = restrict_years(clim, COL_YEAR)\n",
    "\n",
    "    temp_city_year = (\n",
    "        clim.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_TAVE]\n",
    "             .mean()\n",
    "             .rename(columns={COL_TAVE: \"mean_temp_c\"})\n",
    "    )\n",
    "\n",
    "    return temp_city_year[[COL_CITY_ID, COL_YEAR, \"mean_temp_c\"]]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. Air quality → pm25_mean\n",
    "# ============================================================\n",
    "\n",
    "def build_pm25():\n",
    "    \"\"\"\n",
    "    Build city-year pm25_mean from climate_air_quality (daily pm25, adm4).\n",
    "    \"\"\"\n",
    "    air = pd.read_csv(AIRQ_FILE, parse_dates=[COL_DATE], dayfirst=True)\n",
    "    # Expect: adm4_pcode, date, pm25, ...\n",
    "\n",
    "    air = ensure_city_id(air, df_name=\"Air quality\")\n",
    "    air[COL_YEAR] = air[COL_DATE].dt.year\n",
    "    air = restrict_years(air, COL_YEAR)\n",
    "\n",
    "    pm_city_year = (\n",
    "        air.groupby([COL_CITY_ID, COL_YEAR], as_index=False)[COL_PM25]\n",
    "           .mean()\n",
    "           .rename(columns={COL_PM25: \"pm25_mean\"})\n",
    "    )\n",
    "\n",
    "    return pm_city_year[[COL_CITY_ID, COL_YEAR, \"pm25_mean\"]]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. Build final dataset (city-year 2018–2021)\n",
    "# ============================================================\n",
    "\n",
    "def build_final_dataset():\n",
    "    # City-level pop_mean\n",
    "    pop_city = build_city_pop_mean()\n",
    "\n",
    "    # Core pieces\n",
    "    deaths = build_psa_deaths(pop_city)   # diab_deaths, diab_death_rate, pop_mean\n",
    "    night  = build_nightlights()          # nightlights_log\n",
    "    temp   = build_mean_temp()            # mean_temp_c\n",
    "    pm25   = build_pm25()                 # pm25_mean\n",
    "    wealth = build_wealth_and_dummy()     # wealth_index_city, high_poverty\n",
    "    hosp   = build_health_access()        # hospital_nearest_mean\n",
    "\n",
    "    # Start from deaths\n",
    "    df = deaths.copy()\n",
    "\n",
    "    # Merge city-year predictors\n",
    "    for other in [night, temp, pm25, hosp]:\n",
    "        df = df.merge(other, on=[COL_CITY_ID, COL_YEAR], how=\"left\")\n",
    "\n",
    "    # Merge city-level predictors\n",
    "    df = df.merge(wealth, on=COL_CITY_ID, how=\"left\")\n",
    "\n",
    "    # Add city_name from location\n",
    "    loc = load_location()[[COL_CITY_ID, \"city_name\"]].drop_duplicates()\n",
    "    df = df.merge(loc, on=COL_CITY_ID, how=\"left\")\n",
    "\n",
    "    # Keep only rows with non-missing death rate\n",
    "    df = restrict_years(df, COL_YEAR)\n",
    "    df = df[~df[\"diab_death_rate\"].isna()].copy()\n",
    "\n",
    "    # Final columns\n",
    "    final_cols = [\n",
    "        COL_CITY_ID,\n",
    "        \"city_name\",\n",
    "        COL_YEAR,\n",
    "        \"diab_deaths\",\n",
    "        \"diab_death_rate\",\n",
    "        \"pop_mean\",\n",
    "        \"nightlights_log\",\n",
    "        \"mean_temp_c\",\n",
    "        \"pm25_mean\",\n",
    "        \"hospital_nearest_mean\",\n",
    "        \"wealth_index_city\",\n",
    "        \"high_poverty\",\n",
    "    ]\n",
    "\n",
    "    missing = [c for c in final_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        print(\"Warning: these expected columns are missing:\", missing)\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "    df_final = df[[c for c in final_cols if c in df.columns]]\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Building final diabetes regression dataset (city-year 2018–2021)...\")\n",
    "    df_final = build_final_dataset()\n",
    "    print(df_final.head())\n",
    "    print(\"Shape:\", df_final.shape)\n",
    "\n",
    "    out_path = BASE_DIR / \"diabetes_regression_city_year_2018_2021.csv\"\n",
    "    df_final.to_csv(out_path, index=False)\n",
    "    print(\"Saved dataset to:\", out_path)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
